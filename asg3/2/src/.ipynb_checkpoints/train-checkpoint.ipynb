{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of the single layer perceptron model which is trained on an alphabet dataset\n",
    "1. PyTorch Deep Learning library is used for training the model.\n",
    "2. Extended-MNIST dataset is used for training the model. This is character dataset which consists of about 125,000 characters of almost equally distributed 26 alphabets and about 40,000 characters for testing.\n",
    "3. It is an open source dataset which is available on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "class EMNIST_val(Dataset):\n",
    "    def __init__(self, images_tr, labels_tr):\n",
    "        self.images_tr = images_tr\n",
    "        self.labels_tr = labels_tr\n",
    "    def __len__(self):\n",
    "        return len(self.labels_tr)\n",
    "    def one_hot(self,gt):\n",
    "        oh = np.zeros(26)\n",
    "        oh[gt-1] = 1\n",
    "        return oh\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images_tr[index,:]\n",
    "        gt = self.labels_tr[index]\n",
    "        gt = self.one_hot(gt)\n",
    "        sample = {'image': image, 'gt' : gt}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "class EMNIST(Dataset):\n",
    "    def __init__(self, images_tr, labels_tr):\n",
    "        self.images_tr = images_tr\n",
    "        self.labels_tr = labels_tr\n",
    "    def __len__(self):\n",
    "        return len(self.labels_tr)\n",
    "    def one_hot(self,gt):\n",
    "        oh = np.zeros(26)\n",
    "        oh[gt-1] = 1\n",
    "        return oh\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images_tr[index,:]\n",
    "        gt = self.labels_tr[index]\n",
    "        gt = self.one_hot(gt)\n",
    "        sample = {'image': image, 'gt' : gt}\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emnist import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "images_tr, labels_tr = extract_training_samples('letters')\n",
    "images_ts, labels_ts = extract_test_samples('letters')\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "(n,h,w) = images_tr.shape\n",
    "images_tr = images_tr.reshape(n,h*w)\n",
    "images_val = images_tr[99840:,:]\n",
    "labels_val = labels_tr[99840:]\n",
    "num_class = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given below is the architecture of the single layer perceptron neural network\n",
    "1. Each of the images of the dataset are of the size of `28 * 28` pixels.\n",
    "2. These images are flattened to a `(784,1)` vector since we have to feed our image to a single layer linear perceptron. \n",
    "3. The number of outputs after the perceptron is 26 since we have 26 classes, each for 1 alphabet. \n",
    "4. The ground truth is one-hot encoded as a `(26,1)` vector.\n",
    "5. Sigmoid activation function is used\n",
    "5. Mean squared error loss is used to train the model\n",
    "6. We use the adam optimizer to update the weights of the network \n",
    "8. Training and validation accuracy is printed at the end of each epoch. The model is trained for a total of 100 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "class olp(nn.Module):\n",
    "    def __init__(self, input_neurons, output_neurons):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc = nn.Linear(input_neurons, output_neurons)\n",
    "    def forward(self,x):\n",
    "        x = self.fc(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = olp(h*w,num_class)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, betas = (0.9,0.999), weight_decay = 0.00005)\n",
    "model.cpu()\n",
    "num_epochs = 100\n",
    "dataset_train = EMNIST(images_tr, labels_tr)\n",
    "train_loader = DataLoader(dataset_train,batch_size= 1,shuffle=True, num_workers=4)\n",
    "dataset_valid = EMNIST_val(images_val, labels_val)\n",
    "val_loader = DataLoader(dataset_valid, batch_size = 1, shuffle = True, num_workers = 4)\n",
    "acc_tmp = 0\n",
    "for ep in range(num_epochs):\n",
    "    # Setting the model to train mode\n",
    "    loss_agg = 0\n",
    "    acc = 0\n",
    "    model.train\n",
    "    for batch_idx, (subject) in enumerate(train_loader):\n",
    "        # Load the subject and its ground truth\n",
    "        image = subject['image']\n",
    "        mask = subject['gt']\n",
    "        image.cpu()\n",
    "        mask.cpu()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Propagation to get the output from the models\n",
    "        output = model(image.float())\n",
    "        # Computing the loss    \n",
    "        loss = loss_fn(output.double(), mask.double())\n",
    "        # Back Propagation for model to learn\n",
    "        loss.backward()\n",
    "        #Updating the weight values\n",
    "        optimizer.step()\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        loss_agg = loss_agg + loss\n",
    "        output = output.detach().cpu().numpy()\n",
    "        mask = mask.detach().cpu().numpy()\n",
    "        tmp = np.zeros(output.shape)\n",
    "        tmp[:,np.argmax(output)] = 1\n",
    "        acc = acc + np.sum(tmp*mask)\n",
    "    print(\"Train Loss for epoch :\",ep,\"  \",loss_agg/(batch_idx+1))\n",
    "    print(\"Accuracy of Training is: \", acc/(batch_idx+1))\n",
    "    model.eval   \n",
    "    loss_agg_val = 0\n",
    "    acc = 0\n",
    "    for batch_idx, (subject) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            image = subject['image']\n",
    "            mask = subject['gt']\n",
    "            output = model(image.float())\n",
    "            loss = loss_fn(output.double(), mask.double())\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            loss_agg_val = loss_agg_val + loss\n",
    "            output = output.detach().cpu().numpy()\n",
    "            mask = mask.detach().cpu().numpy()\n",
    "            tmp = np.zeros(output.shape)\n",
    "            tmp[:,np.argmax(output)] = 1\n",
    "            acc = acc + np.sum(tmp*mask)\n",
    "\n",
    "    print(\"Validation loss for epoch :\",ep,\" \",loss_agg_val/(batch_idx+1))\n",
    "    print(\"Accuracy of Validation is: \", acc/(batch_idx+1))\n",
    "    if acc>acc_tmp:\n",
    "        acc_tmp = acc\n",
    "        torch.save(model,\"mod.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of training\n",
    "1. The training and validation accuracy are very low, at about 5 % when trained for 100 epochs\n",
    "2. This tells us that the data can not be classfied using just a single layer perceptron.\n",
    "3. This also tells us that the data is not linearly separable.\n",
    "4. Hence, we need atleast 2 layer perceptron network to classify the alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
